#IMPORT LIBRARY
import pandas as pd
import numpy as np

#LOAD DATA
import os
os.chdir('C:\\Users\\NEW\\Desktop\\python\\datasets')
ash = pd.read_csv('data1.csv')
pd.set_option('display.max_columns', None)

#DATA WRANGLING(pre-process)
#outliers removal
ash.boxplot(column=["Item_Outlet_Sales"])
def pintu (data,age):
 Q1 = data[age].quantile(0.25)
 Q3 = data[age].quantile(0.75)
 IQR = Q3 - Q1
 data= data.loc[~((data[age] < (Q1 - 1.5 * IQR)) | (data[age] > (Q3 + 1.5 * IQR))),]
 return data
ash.boxplot(column=["Length of Membership"])
ash = pintu(ash,"Item_Outlet_Sales")

#missing values
ash.isnull().sum()#missing values per variable
ash = ash.dropna() or fillna(mean)

#dummy variables
ak = ash.loc[:,["Item_Fat_Content","Item_Type","Outlet_Size","Outlet_Location_Type","Outlet_Type"]]
ak
ash = ash.drop(["Item_Fat_Content","Item_Type","Outlet_Size","Outlet_Location_Type","Outlet_Type"],axis=1)
ash
dum = pd.get_dummies(ak.astype(str),drop_first=True)
dum
data = pd.concat([ash,dum],axis=1)
data

####replace category to values
#####normalization(0,1)
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(data)
X_scaled = pd.DataFrame(X_scaled)
data = X_scaled.copy()

####train & test data split
X = dataset.drop('Is_Lead', axis=1)
Y = dataset['Is_Lead']

# split the dataset into 70% training and 30% testing
import random
random.seed(100)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30,random_state=0)

len(X_train)#X is all ind variables
len(X_test)#X is all ind variables

len(y_train)# y is dep variable
len(y_test)# y is dep variable

##Tenserflow library
import tenserflow as tf
from tenserflow import keras

##Neural Network
model = keras.sequential([keras.layers.Dense(20,input_shape = (26),activation = "relu"),
                          keras.layers.Dense (15,activation = "relu"),
                          keras.layers.Dense (1,activation = "sigmoid")])

HINT : activation function(function use to grt the output of node)
	1.sigmoid(logistic activation function) - (0,1)dependent variable
	         or softmax - multiclass classification
	2.Tanh(hyperbolic tangent activation function) - (-1 to 1)
	3.reLu(rectified linear unit) - (0 to infinity)

HINT : select the activation function based on dependent variable(data visualize)
 
model.compile (optimizer = "adam",
               loss = "binary_crossentrophy",
               metrics = ["accuracy"])

##fit model
model.fit(x_train,y_train,epochs = 50)
model.evaluate(x_test,y_test)###accuracy

###Prediction
ak = model.predict(x_test)

##CLASSIFICATION REPORT
from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
